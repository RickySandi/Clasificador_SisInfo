{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Habilitar intellisense\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Label\n",
       "0  Once again Mr. Costner has dragged out a movie...   neg\n",
       "1  This is an example of why the majority of acti...   neg\n",
       "2  First of all I hate those moronic rappers, who...   neg\n",
       "3  Not even the Beatles could write songs everyon...   neg\n",
       "4  Brass pictures (movies is not a fitting word f...   neg"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('imdb_dataset.csv',encoding=\"ISO-8859-1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  50000 non-null  object\n",
      " 1   Label   50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# print(data.shape) # (50000, 1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_prueba=data.sample(frac=0.2)\n",
    "\n",
    "\n",
    "#Guardando data -> 20% = 10.000\n",
    "# # #Crear DataFrame de 10.000 \n",
    "# df = pd.DataFrame(poblacion) \n",
    "# muestra = df.sample(n = 10000)\n",
    "# muestra.head() #Es aleatorio, cada vez hay nuevos valores -> Resultados deberian ser parecidos \n",
    "\n",
    "#Exportar DataFrame\n",
    "# data_prueba.to_csv ('imdb_dataset_prueba.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7429</td>\n",
       "      <td>Let's see: there's a civil war, a lost city, a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15594</td>\n",
       "      <td>This two-character drama is extremely well-act...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17577</td>\n",
       "      <td>You don't have to be a tamilian to appreciate ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40506</td>\n",
       "      <td>Documentaries of this kind are often very opin...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>390</td>\n",
       "      <td>It isn't TOO bad, but ultimately it lacks the ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             Review Label\n",
       "0        7429  Let's see: there's a civil war, a lost city, a...   neg\n",
       "1       15594  This two-character drama is extremely well-act...   pos\n",
       "2       17577  You don't have to be a tamilian to appreciate ...   pos\n",
       "3       40506  Documentaries of this kind are often very opin...   pos\n",
       "4         390  It isn't TOO bad, but ultimately it lacks the ...   neg"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('imdb_dataset_prueba.csv',encoding=\"ISO-8859-1\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  10000 non-null  int64 \n",
      " 1   Review      10000 non-null  object\n",
      " 2   Label       10000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# print(data.shape) # (10000, 1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')] #Limpiar la columna Unnamed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let's see: there's a civil war, a lost city, a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This two-character drama is extremely well-act...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You don't have to be a tamilian to appreciate ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Documentaries of this kind are often very opin...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It isn't TOO bad, but ultimately it lacks the ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Label\n",
       "0  Let's see: there's a civil war, a lost city, a...   neg\n",
       "1  This two-character drama is extremely well-act...   pos\n",
       "2  You don't have to be a tamilian to appreciate ...   pos\n",
       "3  Documentaries of this kind are often very opin...   pos\n",
       "4  It isn't TOO bad, but ultimately it lacks the ...   neg"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.info()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_parada = set( nltk.corpus.stopwords.words('english') + list(string.punctuation)+[\"...\",\"..\",\"hr\"])\n",
    "#palabras_parada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanHtml(conHTML):\n",
    "    limpiar_html = re.compile('<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});')\n",
    "    sin_html = re.sub(limpiar_html, '', conHTML)\n",
    "    return sin_html\n",
    "\n",
    "def delete_html(palabras):\n",
    "    array = []\n",
    "    for palabra in  palabras:\n",
    "        deleted_html = cleanHtml(palabra)\n",
    "        array.append(deleted_html)\n",
    "    return array\n",
    "\n",
    "def delete_quotes(palabras):\n",
    "    array = []\n",
    "    for palabra in  palabras:\n",
    "        palabra = palabra.strip(\"'\")\n",
    "        palabra = palabra.strip(\"`\")\n",
    "        array.append(palabra)\n",
    "    return array\n",
    "\n",
    "def tokenize(texto):\n",
    "    texto=texto.lower()\n",
    "    palabras = nltk.word_tokenize(texto)#separa las palabras\n",
    "    return [palabra for palabra in palabras if palabra not in palabras_parada]#quita stopwords\n",
    "def list_to_string(lista):  \n",
    "    str1 = \" \" \n",
    "    return (str1.join(lista)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'let s see s civil war lost city talking gorilla regular gorillas previously unknown species killer albino gorilla powerful laser ever known man lot diamonds lying mined loose sand attack hippos active volcano hot air balloon packed suitcase downed plane s much ve coherent fever dreams  romanian guy picked bunch diamonds lost city looking something mean gorillas seen came nowhere ate somehow talking gorilla back visiting regular gorillas kind earthquake volcano started woman industrialist/doctor built gun using laser big diamond found dead fiance s hand  s blast re looking ammunition pernicious influence michael crichton american entertainment hence world entertainment keep firmly mind extent cynical half-hearted attempt fell face boxoffice sadly men responsible -- crichton sceenwriter john patrick shanley director frank marshall -- probably never lost dime shame mean 1/10'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_comentarios=[]              #Limpieza\n",
    "for index, row in data.iterrows():\n",
    "    \n",
    "    tokenizado=tokenize(row['Review'])\n",
    "    \n",
    "    deleted_html=delete_html(tokenizado)\n",
    "    \n",
    "    delted_quotes=delete_quotes(deleted_html)\n",
    "    \n",
    "    lista=list_to_string(delted_quotes)\n",
    "    \n",
    "    lista_comentarios.append(lista)\n",
    "    \n",
    "lista_comentarios[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "lista_comentarios = np.array(lista_comentarios) #Convirtiendo la lista de cometario a np.array \n",
    "print(type(lista_comentarios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_comentarios.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del lista:  68827\n"
     ]
    }
   ],
   "source": [
    "def get_vocabulary(normalized_corpus): #Devuelve lista ordenada con tokens normalizados\n",
    "    all_tokens = [] \n",
    "    for document in normalized_corpus:\n",
    "        all_tokens.extend(document.split())  \n",
    "    all_tokens_sorted = sorted(set(all_tokens))\n",
    "    \n",
    "    token_and_position = {}\n",
    "    for i, token in enumerate(all_tokens_sorted):\n",
    "        token_and_position[token] = i\n",
    "    \n",
    "    return token_and_position\n",
    "\n",
    "\n",
    "\n",
    "problem_vocabulary = get_vocabulary(lista_comentarios)\n",
    "print(\"Tamaño del lista: \",len(problem_vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem_vocabulary #Lista  con el vocabulario del problema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vector(document, problem_vocabulary):\n",
    "    vector = np.zeros(len(problem_vocabulary),dtype=int)\n",
    "    for token in document.split():\n",
    "        vector[problem_vocabulary[token]] = 1\n",
    "    return vector\n",
    "\n",
    "def one_hot_matrix(lista):\n",
    "    matriz=[]\n",
    "    for i in lista:\n",
    "        matriz.append(one_hot_vector(i, problem_vocabulary))\n",
    "    return matriz\n",
    "        \n",
    "matriz=one_hot_matrix(lista_comentarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 68827)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(type(matriz)) #<class 'list'>\n",
    "matriz = np.array(matriz)\n",
    "matriz.shape \n",
    "\n",
    "# '''68827 es el tamaño del vocabulario del problema'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de comentarios:  10000\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero de comentarios: \" ,len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_diccionario=[]\n",
    "i=0\n",
    "for index, row in data.iterrows():\n",
    "    z = {'tokenizado':matriz[i],'clasificacion':row['Label']}\n",
    "    i=i+1\n",
    "    matriz_diccionario.append(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokenizado': array([0, 0, 0, ..., 0, 0, 0]), 'clasificacion': 'neg'}\n",
      "{'tokenizado': array([0, 0, 0, ..., 0, 0, 0]), 'clasificacion': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "#matriz_diccionario\n",
    "print(matriz_diccionario[0])\n",
    "print(matriz_diccionario[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_entrenamiento=[]\n",
    "for i in matriz_diccionario:\n",
    "    if(i[\"clasificacion\"]==\"pos\"):\n",
    "        lista_entrenamiento.append([i[\"tokenizado\"], 1])\n",
    "    else:\n",
    "        lista_entrenamiento.append([i[\"tokenizado\"], 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 0, 0, ..., 0, 0, 0]), 0]\n",
      "[array([0, 0, 0, ..., 0, 0, 0]), 1]\n"
     ]
    }
   ],
   "source": [
    "# lista_entrenamiento\n",
    "print(lista_entrenamiento[0])\n",
    "print(lista_entrenamiento[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(lista_entrenamiento)\n",
    "#df[0]\n",
    "\n",
    "\n",
    "\n",
    "serie = df[0].apply(pd.Series) #Se puede descomentar \n",
    "#serie[0]\n",
    "\n",
    "\n",
    "serie[\"output\"]=df[1]  #Se puede descomentar \n",
    "# serie[0]            #Se puede descomentar \n",
    "\n",
    "print(type(serie))\n",
    "# serie                 #Data Frame \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68827"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_len=len(problem_vocabulary)\n",
    "mat_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = serie.iloc[:, np.r_[0:mat_len]]\n",
    "y = serie['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 68827) (3000, 68827) (7000,) (3000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training, 30% test\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9953    1\n",
       "3850    1\n",
       "4962    0\n",
       "3886    0\n",
       "5437    0\n",
       "       ..\n",
       "5273    1\n",
       "8014    0\n",
       "8984    0\n",
       "6498    1\n",
       "6327    1\n",
       "Name: output, Length: 3000, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Review Label\n",
      "9953  I remember hearing about this movie and how it...   pos\n",
      "                                                 Review Label\n",
      "3850  Just got my copy of this DVD two disc set and ...   pos\n",
      "                                                 Review Label\n",
      "4962  Quite honestly, The Omega Code is the worst mo...   neg\n",
      "                                                 Review Label\n",
      "3886  Relative to other Columbo movies, this can onl...   neg\n",
      "                                                 Review Label\n",
      "5437  I'm relieved the later reviews have turned sou...   neg\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[[9953]])\n",
    "print(data.loc[[3850]])\n",
    "print(data.loc[[4962]])\n",
    "print(data.loc[[3886]])\n",
    "print(data.loc[[5437]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treeV4=RandomForestClassifier(n_estimators=75)\n",
    "treeV4=RandomForestClassifier(n_estimators=88)\n",
    "#treeV4=RandomForestClassifier(n_estimators=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=88)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeV4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy del clasificador - version 4 : 0.83\n",
      "matriz de confusión del clasificador - version 4: \n",
      " [[1281  307]\n",
      " [ 195 1217]]\n",
      "precision del clasificador - version 4 : 0.80\n",
      "recall del clasificador - version 4 : 0.86\n",
      "f1 del clasificador - version 4 : 0.83\n"
     ]
    }
   ],
   "source": [
    "print('accuracy del clasificador - version 4 : {0:.2f}'.format(accuracy_score(y_test, treeV4.predict(X_test))))\n",
    "# confusion matrix\n",
    "print('matriz de confusión del clasificador - version 4: \\n {0}'.format(confusion_matrix(y_test, treeV4.predict(X_test))))\n",
    "# precision \n",
    "print('precision del clasificador - version 4 : {0:.2f}'.format(precision_score(y_test, treeV4.predict(X_test))))\n",
    "# recall\n",
    "print('recall del clasificador - version 4 : {0:.2f}'.format(recall_score(y_test, treeV4.predict(X_test))))\n",
    "# f1\n",
    "print('f1 del clasificador - version 4 : {0:.2f}'.format(f1_score(y_test, treeV4.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "83% de exactitud > 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo_clasificador = os.path.join(\"Clasificador\", \"tree_v4.pkl\")\n",
    "archivo_clasificador = open(ruta_archivo_clasificador, \"wb\")\n",
    "pickle.dump(treeV4, archivo_clasificador)\n",
    "archivo_clasificador.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_archivo_vocabulario = os.path.join(\"Clasificador\",\"VocabularioProblema.pkl\")\n",
    "\n",
    "#Abrir el archivo para escribir contenido binario\n",
    "archivo_vocabulario = open(ruta_archivo_vocabulario, \"wb\")\n",
    "\n",
    "pickle.dump(problem_vocabulary, archivo_vocabulario,protocol=2)\n",
    "\n",
    "archivo_vocabulario.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
